# üéØ GETTING STARTED

Ch√†o m·ª´ng b·∫°n ƒë·∫øn v·ªõi Medical Chatbot! H∆∞·ªõng d·∫´n n√†y s·∫Ω gi√∫p b·∫°n ch·∫°y ƒë∆∞·ª£c h·ªá th·ªëng trong 10 ph√∫t.

---

## üìã B∆∞·ªõc 1: Ki·ªÉm Tra Y√™u C·∫ßu H·ªá Th·ªëng

### C·∫ßn C√≥
‚úÖ **Python 3.10+**
```powershell
python --version
# N·∫øu ch∆∞a c√≥: Download t·ª´ https://www.python.org/downloads/
```

‚úÖ **Node.js 18+**
```powershell
node --version
# N·∫øu ch∆∞a c√≥: Download t·ª´ https://nodejs.org/
```

‚úÖ **Ollama**
```powershell
ollama --version
# N·∫øu ch∆∞a c√≥: Download t·ª´ https://ollama.ai/download
```

### Ki·ªÉm Tra Disk Space
- Backend dependencies: ~500 MB
- Frontend dependencies: ~300 MB
- Ollama model: ~4-5 GB
- **T·ªïng c·ªông: ~6 GB**

---

## üöÄ B∆∞·ªõc 2: C√†i ƒê·∫∑t Ollama v√† Model

### Windows

1. **Download Ollama:**
   - Truy c·∫≠p: https://ollama.ai/download
   - Download v√† c√†i ƒë·∫∑t Ollama for Windows

2. **Kh·ªüi ƒë·ªông Ollama:**
   - Ollama s·∫Ω t·ª± ch·∫°y sau khi c√†i
   - Ki·ªÉm tra: T√¨m icon Ollama ·ªü system tray

3. **Pull Model:**
```powershell
# M·ªü PowerShell v√† ch·∫°y:
ollama pull mistral:7b

# Ch·ªù download (4-5 GB, m·∫•t 5-10 ph√∫t)
# Ki·ªÉm tra:
ollama list
```

### Linux/Mac
```bash
# Install Ollama
curl -fsSL https://ollama.ai/install.sh | sh

# Pull model
ollama pull mistral:7b

# Verify
ollama list
```

---

## üîß B∆∞·ªõc 3: Setup Backend

### 3.1. M·ªü Terminal v√† Navigate

```powershell
cd D:\ML\Local-RAG\backend
```

### 3.2. T·∫°o Virtual Environment

```powershell
# T·∫°o venv
python -m venv venv

# K√≠ch ho·∫°t (QUAN TR·ªåNG!)
.\venv\Scripts\Activate.ps1

# N·∫øu g·∫∑p l·ªói ExecutionPolicy:
Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

# Ki·ªÉm tra: prompt s·∫Ω c√≥ (venv) ·ªü ƒë·∫ßu
```

### 3.3. Install Dependencies

```powershell
# Upgrade pip
python -m pip install --upgrade pip

# Install packages (m·∫•t 2-3 ph√∫t)
pip install -r requirements.txt
```

**‚è≥ Ch·ªù c√†i ƒë·∫∑t... ƒê√¢y l√† l√∫c t·ªët ƒë·ªÉ pha c√† ph√™!**

### 3.4. Ki·ªÉm Tra Installation

```powershell
# Test system
python test_system.py

# K·∫øt qu·∫£ mong ƒë·ª£i:
# ‚úÖ VectorStore: PASS
# ‚úÖ LLM Service: PASS
# ‚úÖ PDF Processor: PASS
# ‚úÖ End-to-End: PASS
```

### 3.5. Kh·ªüi ƒê·ªông Backend

```powershell
python main.py

# Output mong ƒë·ª£i:
# üöÄ Kh·ªüi ƒë·ªông ·ª©ng d·ª•ng Medical Chatbot...
# ‚úÖ ChromaDB initialized
# ‚úÖ Ollama connection OK
# ‚úÖ Kh·ªüi ƒë·ªông th√†nh c√¥ng!
# INFO: Uvicorn running on http://0.0.0.0:8000
```

**üéâ Backend ƒë√£ s·∫µn s√†ng!** ƒê·ªÉ terminal n√†y ch·∫°y v√† m·ªü terminal m·ªõi.

---

## üé® B∆∞·ªõc 4: Setup Frontend

### 4.1. M·ªü Terminal M·ªõi

```powershell
# Navigate ƒë·∫øn frontend
cd D:\ML\Local-RAG\frontend
```

### 4.2. Install Dependencies

```powershell
# Install npm packages (m·∫•t 1-2 ph√∫t)
npm install
```

### 4.3. Kh·ªüi ƒê·ªông Frontend

```powershell
npm run dev

# Output mong ƒë·ª£i:
#   VITE v5.0.8  ready in 1234 ms
#
#   ‚ûú  Local:   http://localhost:3000/
#   ‚ûú  Network: use --host to expose
```

**üéâ Frontend ƒë√£ s·∫µn s√†ng!**

---

## üåê B∆∞·ªõc 5: Truy C·∫≠p ·ª®ng D·ª•ng

### M·ªü Browser

Truy c·∫≠p: **http://localhost:3000**

B·∫°n s·∫Ω th·∫•y:
- ‚úÖ Header v·ªõi "Medical Chatbot" 
- ‚úÖ Status indicator m√†u xanh "ƒêang ho·∫°t ƒë·ªông"
- ‚úÖ Welcome message
- ‚úÖ Sample questions ƒë·ªÉ click

### Ki·ªÉm Tra API Docs

Truy c·∫≠p: **http://localhost:8000/docs**

B·∫°n s·∫Ω th·∫•y Swagger UI v·ªõi t·∫•t c·∫£ endpoints.

---

## üí¨ B∆∞·ªõc 6: Test Chatbot

### Test 1: Chat ƒê∆°n Gi·∫£n (Kh√¥ng RAG)

1. Click v√†o sample question: **"Tri·ªáu ch·ª©ng c·ªßa b·ªánh c·∫£m c√∫m l√† g√¨?"**
2. Ch·ªù response streaming
3. Xem c√¢u tr·∫£ l·ªùi xu·∫•t hi·ªán t·ª´ng ch·ªØ

### Test 2: Upload Document

1. Click n√∫t **"Upload PDF"** ·ªü header
2. Ch·ªçn m·ªôt file PDF y t·∫ø (ho·∫∑c t·∫°o file test)
3. Upload v√† ch·ªù processing
4. Xem message: "ƒê√£ x·ª≠ l√Ω th√†nh c√¥ng X chunks"

### Test 3: Chat V·ªõi RAG

1. G√µ c√¢u h·ªèi li√™n quan ƒë·∫øn document v·ª´a upload
2. Xem response c√≥ **"üìö Ngu·ªìn tham kh·∫£o"** ·ªü ƒë·∫ßu
3. Ki·ªÉm tra ngu·ªìn ƒë∆∞·ª£c cite

---

## üéä Ho√†n Th√†nh!

B·∫°n ƒë√£ setup th√†nh c√¥ng! B√¢y gi·ªù b·∫°n c√≥:

‚úÖ Backend API running (port 8000)  
‚úÖ Frontend UI running (port 3000)  
‚úÖ Ollama model ready  
‚úÖ ChromaDB initialized  
‚úÖ Chat interface working  
‚úÖ RAG pipeline functional  

---

## üéØ C√°c B∆∞·ªõc Ti·∫øp Theo

### 1. Th√™m T√†i Li·ªáu Y T·∫ø

Copy PDF files v√†o folder `data/`:
```powershell
copy medical_books.pdf D:\ML\Local-RAG\data\
```

Sau ƒë√≥ reindex:
```powershell
curl -X POST http://localhost:8000/documents/reindex
```

### 2. T√πy Ch·ªânh Model

Trong `backend\.env`:
```env
# Th·ª≠ model kh√°c
OLLAMA_MODEL=llama3.1:8b

# ƒêi·ªÅu ch·ªânh parameters
TEMPERATURE=0.5      # S√°ng t·∫°o h∆°n
MAX_TOKENS=4096      # Response d√†i h∆°n
```

Restart backend ƒë·ªÉ √°p d·ª•ng.

### 3. Customize UI

Trong `frontend\src\components\`:
- `Header.jsx` - ƒê·ªïi title, logo
- `App.jsx` - Th√™m features
- `index.css` - ƒê·ªïi colors, styles

### 4. Deploy Production

Xem [DEPLOYMENT.md](DEPLOYMENT.md) ƒë·ªÉ bi·∫øt chi ti·∫øt.

---

## üÜò G·∫∑p V·∫•n ƒê·ªÅ?

### Backend Kh√¥ng Start

```powershell
# Check Ollama
ollama list

# Check port
netstat -ano | findstr :8000

# View logs
python main.py 2>&1 | tee logs.txt
```

### Frontend Kh√¥ng Start

```powershell
# Clear cache
rm -r node_modules
npm install

# Check backend
curl http://localhost:8000/health
```

### Chat Kh√¥ng Ho·∫°t ƒê·ªông

1. **Check browser console (F12)**
   - C√≥ l·ªói CORS?
   - API connection failed?

2. **Check backend logs**
   - Ollama connected?
   - Model loaded?

3. **Test API directly**
   ```powershell
   curl -X POST http://localhost:8000/chat `
     -H "Content-Type: application/json" `
     -d '{\"message\":\"test\",\"use_rag\":false}'
   ```

### ƒê·ªçc Th√™m

- [DEBUGGING.md](DEBUGGING.md) - Troubleshooting guide
- [README.md](README.md) - Full documentation
- [QUICKSTART.md](QUICKSTART.md) - Quick reference

---

## üìû C·∫ßn Tr·ª£ Gi√∫p?

**Documentation:**
- README.md - Full docs
- API Docs - http://localhost:8000/docs

**Community:**
- GitHub Issues
- Discord (coming soon)

**Quick Commands:**
```powershell
# Start everything
.\start.bat              # Windows
./start.sh               # Linux/Mac

# Check health
curl http://localhost:8000/health

# View logs
Get-Content logs.txt -Tail 50
```

---

## üéì Learning More

**Ollama:**
- Models: https://ollama.ai/library
- Docs: https://github.com/ollama/ollama

**FastAPI:**
- Tutorial: https://fastapi.tiangolo.com/tutorial/

**React:**
- Learn: https://react.dev/learn

**RAG:**
- Guide: https://www.pinecone.io/learn/retrieval-augmented-generation/

---

**Ch√∫c b·∫°n code vui v·∫ª! üöÄ**